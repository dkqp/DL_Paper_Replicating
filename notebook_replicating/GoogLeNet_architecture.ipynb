{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GoogLeNet (Inception model)\n",
    "### Reference\n",
    "Christian Szegedy, et al., Going deeper with convolutions, CVPR, 2014. [link](https://arxiv.org/pdf/1409.4842.pdf)\n",
    "### Contents\n",
    "* enlarging network without overfitting or extremely increased parameters\n",
    "* key is ultimate moving from fully connected to sparsely connected architectures\n",
    "### Keys\n",
    "* parallel filters and concatenation\n",
    "* channel reduction and projection for computational efficiency\n",
    "* every basic convolution includes batch-normalization and ReLU rectification (even the 1-by-1 reductions)\n",
    "* add auxiliary classifiers at the intermediate layers as well as at the end of the model\n",
    "* losses from the auxiliary classifier are weighted by 0.3 to be added to the total loss\n",
    "* <img src='../etc/images/Googlenet-1.png' width='500'>\n",
    "* <img src='../etc/images/Googlenet-2.png' width='500'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. basic_convolution_block: n-by-n convolution + batch-normalization + ReLU\n",
    "2. inception_block: 4 branches concatenated\n",
    "3. auxiliary_block: average pooling + reduction + fully connected + dropout + classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class basic_conv_block(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int,\n",
    "        padding: int = 0,\n",
    "        stride: int = 1\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=padding,\n",
    "            stride=stride,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(num_features=out_channels, eps=0.001)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inception_block(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        channels_1by1: int,\n",
    "        channels_3by3_reduction: int,\n",
    "        channels_3by3: int,\n",
    "        channels_5by5_reduction: int,\n",
    "        channels_5by5: int,\n",
    "        channels_proj: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.branch1 = basic_conv_block(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=channels_1by1,\n",
    "            kernel_size=1\n",
    "        )\n",
    "        self.branch2 = nn.Sequential(\n",
    "            basic_conv_block(\n",
    "              in_channels=in_channels,\n",
    "              out_channels=channels_3by3_reduction,\n",
    "              kernel_size=1\n",
    "            ),\n",
    "            basic_conv_block(\n",
    "              in_channels=channels_3by3_reduction,\n",
    "              out_channels=channels_3by3,\n",
    "              kernel_size=3,\n",
    "              padding=1\n",
    "            )\n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            basic_conv_block(\n",
    "              in_channels=in_channels,\n",
    "              out_channels=channels_5by5_reduction,\n",
    "              kernel_size=1\n",
    "            ),\n",
    "            basic_conv_block(\n",
    "              in_channels=channels_5by5_reduction,\n",
    "              out_channels=channels_5by5,\n",
    "              kernel_size=5,\n",
    "              padding=2\n",
    "            )\n",
    "        )\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(\n",
    "              kernel_size=3,\n",
    "              padding=1,\n",
    "              stride=1\n",
    "            ),\n",
    "            basic_conv_block(\n",
    "              in_channels=in_channels,\n",
    "              out_channels=channels_proj,\n",
    "              kernel_size=1\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "        branch3 = self.branch3(x)\n",
    "        branch4 = self.branch4(x)\n",
    "\n",
    "        return torch.concat([branch1, branch2, branch3, branch4], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class auxiliary_block(nn.Module):\n",
    "    def __init__(self, in_channels: int, num_features: int) -> None:\n",
    "        super().__init__()\n",
    "        self.average_pooling = nn.AvgPool2d(\n",
    "            kernel_size=5,\n",
    "            stride=3\n",
    "        )\n",
    "        self.reduction = basic_conv_block(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=128,\n",
    "            kernel_size=1\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                in_features=4*4*128,\n",
    "                out_features=1024\n",
    "            ),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=0.7)\n",
    "        self.fc2 = nn.Linear(\n",
    "            in_features=1024,\n",
    "            out_features=num_features\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.average_pooling(x)\n",
    "        x = self.reduction(x)\n",
    "        x = nn.Flatten()(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self, num_features: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv_pool_layer1 = nn.Sequential(\n",
    "            basic_conv_block(\n",
    "              in_channels=3,\n",
    "              out_channels=64,\n",
    "              kernel_size=7,\n",
    "              padding=3,\n",
    "              stride=2\n",
    "            ),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                ceil_mode=True\n",
    "            )\n",
    "        )\n",
    "        self.conv_pool_layer2 = nn.Sequential(\n",
    "            basic_conv_block(\n",
    "              in_channels=64,\n",
    "              out_channels=64,\n",
    "              kernel_size=1\n",
    "            ),\n",
    "            basic_conv_block(\n",
    "              in_channels=64,\n",
    "              out_channels=192,\n",
    "              kernel_size=3,\n",
    "              padding=1\n",
    "            ),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                ceil_mode=True\n",
    "            )\n",
    "        )\n",
    "        self.inception_layer3a = inception_block(\n",
    "            in_channels=192,\n",
    "            channels_1by1=64,\n",
    "            channels_3by3_reduction=96,\n",
    "            channels_3by3=128,\n",
    "            channels_5by5_reduction=16,\n",
    "            channels_5by5=32,\n",
    "            channels_proj=32\n",
    "        )\n",
    "        self.inception_layer3b = inception_block(\n",
    "            in_channels=256,\n",
    "            channels_1by1=128,\n",
    "            channels_3by3_reduction=128,\n",
    "            channels_3by3=192,\n",
    "            channels_5by5_reduction=32,\n",
    "            channels_5by5=96,\n",
    "            channels_proj=64\n",
    "        )\n",
    "        self.max_pool3 = nn.MaxPool2d(\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            ceil_mode=True\n",
    "        )\n",
    "        self.inception_layer4a = inception_block(\n",
    "            in_channels=480,\n",
    "            channels_1by1=192,\n",
    "            channels_3by3_reduction=96,\n",
    "            channels_3by3=208,\n",
    "            channels_5by5_reduction=16,\n",
    "            channels_5by5=48,\n",
    "            channels_proj=64\n",
    "        )\n",
    "        self.inception_layer4b = inception_block(\n",
    "            in_channels=512,\n",
    "            channels_1by1=160,\n",
    "            channels_3by3_reduction=112,\n",
    "            channels_3by3=224,\n",
    "            channels_5by5_reduction=24,\n",
    "            channels_5by5=64,\n",
    "            channels_proj=64\n",
    "        )\n",
    "        self.inception_layer4c = inception_block(\n",
    "            in_channels=512,\n",
    "            channels_1by1=128,\n",
    "            channels_3by3_reduction=128,\n",
    "            channels_3by3=256,\n",
    "            channels_5by5_reduction=24,\n",
    "            channels_5by5=64,\n",
    "            channels_proj=64\n",
    "        )\n",
    "        self.inception_layer4d = inception_block(\n",
    "            in_channels=512,\n",
    "            channels_1by1=112,\n",
    "            channels_3by3_reduction=144,\n",
    "            channels_3by3=288,\n",
    "            channels_5by5_reduction=32,\n",
    "            channels_5by5=64,\n",
    "            channels_proj=64\n",
    "        )\n",
    "        self.inception_layer4e = inception_block(\n",
    "            in_channels=528,\n",
    "            channels_1by1=256,\n",
    "            channels_3by3_reduction=160,\n",
    "            channels_3by3=320,\n",
    "            channels_5by5_reduction=32,\n",
    "            channels_5by5=128,\n",
    "            channels_proj=128\n",
    "        )\n",
    "        self.max_pool4 = nn.MaxPool2d(\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            ceil_mode=True\n",
    "        )\n",
    "        self.inception_layer5a = inception_block(\n",
    "            in_channels=832,\n",
    "            channels_1by1=256,\n",
    "            channels_3by3_reduction=160,\n",
    "            channels_3by3=320,\n",
    "            channels_5by5_reduction=32,\n",
    "            channels_5by5=128,\n",
    "            channels_proj=128\n",
    "        )\n",
    "        self.inception_layer5b = inception_block(\n",
    "            in_channels=832,\n",
    "            channels_1by1=384,\n",
    "            channels_3by3_reduction=192,\n",
    "            channels_3by3=384,\n",
    "            channels_5by5_reduction=48,\n",
    "            channels_5by5=128,\n",
    "            channels_proj=128\n",
    "        )\n",
    "        self.average_pool = nn.AvgPool2d(\n",
    "            kernel_size=7\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.classifier = nn.Linear(in_features=1024, out_features=num_features)\n",
    "        self.auxiliary1 = auxiliary_block(in_channels=512, num_features=num_features)\n",
    "        self.auxiliary2 = auxiliary_block(in_channels=528, num_features=num_features)\n",
    "\n",
    "    def forward(self, x, aux: bool = True):\n",
    "        x = self.conv_pool_layer1(x)\n",
    "\n",
    "        x = self.conv_pool_layer2(x)\n",
    "\n",
    "        x = self.inception_layer3a(x)\n",
    "        x = self.inception_layer3b(x)\n",
    "        x = self.max_pool3(x)\n",
    "\n",
    "        x = self.inception_layer4a(x)\n",
    "        aux1 = None\n",
    "        if aux:\n",
    "            aux1 = self.auxiliary1(x)\n",
    "        x = self.inception_layer4b(x)\n",
    "        x = self.inception_layer4c(x)\n",
    "        x = self.inception_layer4d(x)\n",
    "        aux2 = None\n",
    "        if aux:\n",
    "            aux2 = self.auxiliary2(x)\n",
    "        x = self.inception_layer4e(x)\n",
    "        x = self.max_pool3(x)\n",
    "\n",
    "        x = self.inception_layer5a(x)\n",
    "        x = self.inception_layer5b(x)\n",
    "        x = self.average_pool(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = nn.Flatten()(x)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return (aux1, aux2, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GoogLeNet(\n",
       "  (conv_pool_layer1): Sequential(\n",
       "    (0): basic_conv_block(\n",
       "      (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  )\n",
       "  (conv_pool_layer2): Sequential(\n",
       "    (0): basic_conv_block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): basic_conv_block(\n",
       "      (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  )\n",
       "  (inception_layer3a): inception_block(\n",
       "    (branch1): basic_conv_block(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): basic_conv_block(\n",
       "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): basic_conv_block(\n",
       "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception_layer3b): inception_block(\n",
       "    (branch1): basic_conv_block(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): basic_conv_block(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): basic_conv_block(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (max_pool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception_layer4a): inception_block(\n",
       "    (branch1): basic_conv_block(\n",
       "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): basic_conv_block(\n",
       "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): basic_conv_block(\n",
       "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception_layer4b): inception_block(\n",
       "    (branch1): basic_conv_block(\n",
       "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): basic_conv_block(\n",
       "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): basic_conv_block(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception_layer4c): inception_block(\n",
       "    (branch1): basic_conv_block(\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): basic_conv_block(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): basic_conv_block(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception_layer4d): inception_block(\n",
       "    (branch1): basic_conv_block(\n",
       "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): basic_conv_block(\n",
       "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): basic_conv_block(\n",
       "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception_layer4e): inception_block(\n",
       "    (branch1): basic_conv_block(\n",
       "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): basic_conv_block(\n",
       "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): basic_conv_block(\n",
       "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (max_pool4): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception_layer5a): inception_block(\n",
       "    (branch1): basic_conv_block(\n",
       "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): basic_conv_block(\n",
       "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): basic_conv_block(\n",
       "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception_layer5b): inception_block(\n",
       "    (branch1): basic_conv_block(\n",
       "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): basic_conv_block(\n",
       "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): basic_conv_block(\n",
       "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): basic_conv_block(\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (average_pool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=101, bias=True)\n",
       "  (auxiliary1): auxiliary_block(\n",
       "    (average_pooling): AvgPool2d(kernel_size=5, stride=3, padding=0)\n",
       "    (reduction): basic_conv_block(\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (fc1): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.7, inplace=False)\n",
       "    (fc2): Linear(in_features=1024, out_features=101, bias=True)\n",
       "  )\n",
       "  (auxiliary2): auxiliary_block(\n",
       "    (average_pooling): AvgPool2d(kernel_size=5, stride=3, padding=0)\n",
       "    (reduction): basic_conv_block(\n",
       "      (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (fc1): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.7, inplace=False)\n",
       "    (fc2): Linear(in_features=1024, out_features=101, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GoogLeNet(num_features=101)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "GoogLeNet                                --\n",
       "├─Sequential: 1-1                        9,536\n",
       "├─Sequential: 1-2                        115,200\n",
       "├─inception_block: 1-3                   164,064\n",
       "├─inception_block: 1-4                   389,376\n",
       "├─MaxPool2d: 1-5                         --\n",
       "├─inception_block: 1-6                   376,800\n",
       "├─inception_block: 1-7                   449,808\n",
       "├─inception_block: 1-8                   510,768\n",
       "├─inception_block: 1-9                   606,080\n",
       "├─inception_block: 1-10                  869,376\n",
       "├─MaxPool2d: 1-11                        --\n",
       "├─inception_block: 1-12                  1,044,480\n",
       "├─inception_block: 1-13                  1,445,344\n",
       "├─AvgPool2d: 1-14                        --\n",
       "├─Dropout: 1-15                          --\n",
       "├─Linear: 1-16                           103,525\n",
       "├─auxiliary_block: 1-17                  2,267,493\n",
       "├─auxiliary_block: 1-18                  2,269,541\n",
       "=================================================================\n",
       "Total params: 10,621,391\n",
       "Trainable params: 10,621,391\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 101])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn((2, 3, 224, 224)))[2].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GoogLeNet model for training Food101 datasets\n",
    "* number of parameters: 10,621,391"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from python_scripts import model_builder, engine, data_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food101_transforms_train = transforms.Compose([\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.AutoAugment(transforms.AutoAugmentPolicy.IMAGENET),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "      [0.485, 0.456, 0.406],\n",
    "      [0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "food101_transforms_test = transforms.Compose([\n",
    "    transforms.Resize(225),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "      [0.485, 0.456, 0.406],\n",
    "      [0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_list = [1e-4]\n",
    "weight_decay_list = [1e-4]\n",
    "epochs_list = [5]\n",
    "batch_size_list = [16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../data/extracted')\n",
    "\n",
    "train_data_food101 = datasets.Food101(\n",
    "    root=data_dir,\n",
    "    split='train',\n",
    "    transform=food101_transforms_train,\n",
    "    download=True\n",
    ")\n",
    "test_data_food101 = datasets.Food101(\n",
    "    root=data_dir,\n",
    "    split='test',\n",
    "    transform=food101_transforms_test,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "class_names_food101 = train_data_food101.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def googlenet_model_generator(weights=None):\n",
    "    return model_builder.GoogLeNet(num_features=len(class_names_food101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Splitting dataset of length 75750 into splits of size: 75750 and 0\n",
      "[INFO] Splitting dataset of length 25250 into splits of size: 25250 and 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13890058098f4065afddf0df6ebe5f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train_loss: 4.4056, Train_acc: 0.0417 | Test_loss: 3.9164, Test_acc: 0.1005\n",
      "Epoch: 1 | Train_loss: 4.1334, Train_acc: 0.0781 | Test_loss: 3.5720, Test_acc: 0.1563\n",
      "Epoch: 2 | Train_loss: 3.9022, Train_acc: 0.1161 | Test_loss: 3.2041, Test_acc: 0.2145\n",
      "Epoch: 3 | Train_loss: 3.6619, Train_acc: 0.1569 | Test_loss: 2.8273, Test_acc: 0.2963\n",
      "Epoch: 4 | Train_loss: 3.4637, Train_acc: 0.1954 | Test_loss: 2.5758, Test_acc: 0.3486\n"
     ]
    }
   ],
   "source": [
    "train_dataset, _ = data_setup.split_dataset(\n",
    "    dataset=train_data_food101,\n",
    "    split_size=1, # you can start with small number of train set to check normality at first\n",
    "    seed=42\n",
    ")\n",
    "test_dataset, _ = data_setup.split_dataset(\n",
    "    dataset=test_data_food101,\n",
    "    split_size=1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "tuning_results = engine.HP_tune_train(\n",
    "    model=None,\n",
    "    model_generator=googlenet_model_generator,\n",
    "    model_weights=None,\n",
    "    model_name='GoogLeNet_food101',\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    learning_rate_list=learning_rate_list,\n",
    "    weight_decay_list=weight_decay_list,\n",
    "    epochs_list=epochs_list,\n",
    "    batch_size_list=batch_size_list,\n",
    "    is_tensorboard_writer=False,\n",
    "    device=device,\n",
    "    gradient_accumulation_num=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
